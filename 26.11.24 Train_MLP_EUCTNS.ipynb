{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing classificiation of primary endpoint type in datasets using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np # Don't think I need this but it's just habit at this point\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, up til now I have yet to save a clean CSV file of the EUCT-NS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the untouched EUCT-NS dataset\n",
    "df = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\untouched_euct_ns.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EudraCT_No                                              Title Phase  \\\n",
      "0  2018-003243-39  A Phase 3, Randomized, Double-Blind, Placebo-C...     3   \n",
      "1  2009-016138-29  âRandomized, Multicenter, Open-label, Phase ...   iii   \n",
      "2  2016-000474-38  A Multicenter, 2-Cohort Trial to First Assess ...     0   \n",
      "3  2014-000418-75  A Multicenter, Multinational, Randomized, Doub...     0   \n",
      "4  2012-002933-12  A Phase II pilot study to explore treatment wi...    ii   \n",
      "\n",
      "                                           Objective   End_date  Sample_size  \\\n",
      "0  The primary purpose of this study is to evalua...        NaN          175   \n",
      "1  To compare the efficacy of plitidepsin in comb...  20-Nov-17          255   \n",
      "2  To demonstrate that fenfluramine hydrochloride...  05-Jun-18           87   \n",
      "3  The primary objective of this study was to ass...  19-Jun-18          352   \n",
      "4  To determine whether patients taking a medicin...  10-Dec-18            8   \n",
      "\n",
      "                                         pr_endpoint  \\\n",
      "0  Primary: Change From Baseline In Myasthenia Gr...   \n",
      "1  Primary: Progression-free Survival (Independen...   \n",
      "2  Primary: Change in Convulsive Seizure Frequenc...   \n",
      "3  Primary: Change From Baseline in UHDRS-TMS at ...   \n",
      "4                                Primary: Workload',   \n",
      "\n",
      "                                endpoint_description  \\\n",
      "0  MG-ADL: 8-point questionnaire focusing on rele...   \n",
      "1  The primary study analysis was based on extern...   \n",
      "2  Baseline-adjusted in CSF (mean number of convu...   \n",
      "3  UHDRS assess motor function, cognition, behavi...   \n",
      "4  All participants cycled on a cycle ergometer. ...   \n",
      "\n",
      "                    Treatment LT_followup  manual_label  \n",
      "0                 Ravulizumab          No             0  \n",
      "1                     Aplidin          No             2  \n",
      "2  fenfluramine hydrochloride         Yes             0  \n",
      "3                     Placebo          No             0  \n",
      "4            Sodium Valproate          No             1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.lower()  # Convert to lower case\n",
    "    text = text.split()  # Split into words\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stopwords.words('english')]  # Lemmatize and remove stopwords # Get rid of primary as a stop word\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def strip_accents(text):\n",
    "    return ''. join(word for word in unicodedata.normalize ('NFD', text)\n",
    "                     if unicodedata.category(word) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].apply(preprocess_text)\n",
    "df['Objective'] = df['Objective'].apply(preprocess_text)\n",
    "df['pr_endpoint'] = df['pr_endpoint'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['endpoint_description'] = df['endpoint_description'].apply(str)\n",
    "df['endpoint_description'] = df['endpoint_description'].apply(preprocess_text)\n",
    "df['Title'] = df['Title'].apply(strip_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\s2421127\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_primary(text):\n",
    "    stop = nltk.corpus.stopwords.words('english')\n",
    "    stop.append(\"primary\")\n",
    "    return ' '.join([word for word in text.split() if word not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pr_endpoint'] = df['pr_endpoint'].apply(no_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EudraCT_No</th>\n",
       "      <th>Title</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Objective</th>\n",
       "      <th>End_date</th>\n",
       "      <th>Sample_size</th>\n",
       "      <th>pr_endpoint</th>\n",
       "      <th>endpoint_description</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>LT_followup</th>\n",
       "      <th>manual_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-003243-39</td>\n",
       "      <td>phase 3 randomized double blind placebo contro...</td>\n",
       "      <td>3</td>\n",
       "      <td>primary purpose study evaluate safety efficacy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>change baseline myasthenia gravis activity dai...</td>\n",
       "      <td>mg adl 8 point questionnaire focusing relevant...</td>\n",
       "      <td>Ravulizumab</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-016138-29</td>\n",
       "      <td>randomized multicenter open label phase iii st...</td>\n",
       "      <td>iii</td>\n",
       "      <td>compare efficacy plitidepsin combination dexam...</td>\n",
       "      <td>20-Nov-17</td>\n",
       "      <td>255</td>\n",
       "      <td>progression free survival independent review c...</td>\n",
       "      <td>primary study analysis based externally assess...</td>\n",
       "      <td>Aplidin</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-000474-38</td>\n",
       "      <td>multicenter 2 cohort trial first as pharmacoki...</td>\n",
       "      <td>0</td>\n",
       "      <td>demonstrate fenfluramine hydrochloride superio...</td>\n",
       "      <td>05-Jun-18</td>\n",
       "      <td>87</td>\n",
       "      <td>change convulsive seizure frequency csf baseli...</td>\n",
       "      <td>baseline adjusted csf mean number convulsive s...</td>\n",
       "      <td>fenfluramine hydrochloride</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-000418-75</td>\n",
       "      <td>multicenter multinational randomized double bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>primary objective study as efficacy laquinimod...</td>\n",
       "      <td>19-Jun-18</td>\n",
       "      <td>352</td>\n",
       "      <td>change baseline uhdrs tm week 52</td>\n",
       "      <td>uhdrs as motor function cognition behaviour fu...</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-002933-12</td>\n",
       "      <td>phase ii pilot study explore treatment sodium ...</td>\n",
       "      <td>ii</td>\n",
       "      <td>determine whether patient taking medicine call...</td>\n",
       "      <td>10-Dec-18</td>\n",
       "      <td>8</td>\n",
       "      <td>workload</td>\n",
       "      <td>participant cycled cycle ergometer oxygen cons...</td>\n",
       "      <td>Sodium Valproate</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EudraCT_No                                              Title Phase  \\\n",
       "0  2018-003243-39  phase 3 randomized double blind placebo contro...     3   \n",
       "1  2009-016138-29  randomized multicenter open label phase iii st...   iii   \n",
       "2  2016-000474-38  multicenter 2 cohort trial first as pharmacoki...     0   \n",
       "3  2014-000418-75  multicenter multinational randomized double bl...     0   \n",
       "4  2012-002933-12  phase ii pilot study explore treatment sodium ...    ii   \n",
       "\n",
       "                                           Objective   End_date  Sample_size  \\\n",
       "0  primary purpose study evaluate safety efficacy...        NaN          175   \n",
       "1  compare efficacy plitidepsin combination dexam...  20-Nov-17          255   \n",
       "2  demonstrate fenfluramine hydrochloride superio...  05-Jun-18           87   \n",
       "3  primary objective study as efficacy laquinimod...  19-Jun-18          352   \n",
       "4  determine whether patient taking medicine call...  10-Dec-18            8   \n",
       "\n",
       "                                         pr_endpoint  \\\n",
       "0  change baseline myasthenia gravis activity dai...   \n",
       "1  progression free survival independent review c...   \n",
       "2  change convulsive seizure frequency csf baseli...   \n",
       "3                   change baseline uhdrs tm week 52   \n",
       "4                                           workload   \n",
       "\n",
       "                                endpoint_description  \\\n",
       "0  mg adl 8 point questionnaire focusing relevant...   \n",
       "1  primary study analysis based externally assess...   \n",
       "2  baseline adjusted csf mean number convulsive s...   \n",
       "3  uhdrs as motor function cognition behaviour fu...   \n",
       "4  participant cycled cycle ergometer oxygen cons...   \n",
       "\n",
       "                    Treatment LT_followup  manual_label  \n",
       "0                 Ravulizumab          No             0  \n",
       "1                     Aplidin          No             2  \n",
       "2  fenfluramine hydrochloride         Yes             0  \n",
       "3                     Placebo          No             0  \n",
       "4            Sodium Valproate          No             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('euct_ns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # Need this to save the fitted vectorizer when I apply it to the NS-HRA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "euct_ns = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\euct_ns.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['Title', 'Objective', 'pr_endpoint', 'endpoint_description']\n",
    "X = euct_ns[text_columns] \n",
    "y = euct_ns['manual_label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is words so needs to be converted into numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_train.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'tfidf_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler(with_mean=False) # Sparse dataset\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_train.pkl']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLPClassifier model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
    "                    max_iter=1000, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.68%\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 2 2 2 2 1 0 0 0 0 0 0 1 2 1 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred) # There is no cases of intermediate outcomes in the pred set. Do I re-run it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\"class_report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s2421127\\AppData\\Local\\miniconda3\\envs\\clustering_endpoints\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\s2421127\\AppData\\Local\\miniconda3\\envs\\clustering_endpoints\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\s2421127\\AppData\\Local\\miniconda3\\envs\\clustering_endpoints\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\\"class_report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply MLP model to NS-HRA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_11.csv', encoding='unicode_escape')\n",
    "twelve = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_12.csv', encoding='unicode_escape')\n",
    "thirteen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_13.csv', encoding='unicode_escape')\n",
    "fourteen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_14.csv', encoding='unicode_escape')\n",
    "fifteen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_15.csv', encoding='unicode_escape')\n",
    "sixteen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_16.csv', encoding='unicode_escape')\n",
    "seventeen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_17.csv', encoding='unicode_escape')\n",
    "eighteen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_18.csv', encoding='unicode_escape')\n",
    "nineteen = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_19.csv', encoding='unicode_escape')\n",
    "twenty = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra_20.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_hra_untouched = pd.concat([eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ns_hra_untouched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_hra_untouched.to_csv('untouched_ns_hra.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\untouched_ns_hra.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Objective</th>\n",
       "      <th>End_date</th>\n",
       "      <th>Sample_size</th>\n",
       "      <th>1ry_endpoint</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>LT_followup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRAS_projectID_57754</td>\n",
       "      <td>Phase II, multicenter, randomized, adaptive, d...</td>\n",
       "      <td>ii</td>\n",
       "      <td>To assess the efficacy and the safety of liqui...</td>\n",
       "      <td>31/05/2013 00:00</td>\n",
       "      <td>150.0</td>\n",
       "      <td>The primary outcome measure is the Motor Funct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjects will participate in the study for a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IRAS_projectID_82035</td>\n",
       "      <td>A Randomized, Controlled, Long-term Safety Stu...</td>\n",
       "      <td>0</td>\n",
       "      <td>The principal objective of the study is to ass...</td>\n",
       "      <td>30/09/2013 00:00</td>\n",
       "      <td>450.0</td>\n",
       "      <td>The primary endpoint in this study is the chan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjects will be involved in this study for ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRAS_projectID_64187</td>\n",
       "      <td>A Randomized, Double-Blind, Double-Dummy, Para...</td>\n",
       "      <td>0</td>\n",
       "      <td>To assess whether the efficacy of Ocrelizumab ...</td>\n",
       "      <td>31/03/2015 00:00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>The primary efficacy analysis for this trial w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Screening 2 weeks\\nTreatment phase 96 weeks\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IRAS_projectID_72673</td>\n",
       "      <td>Multi-Centre, Open-Label, Randomised Trial Inv...</td>\n",
       "      <td>0</td>\n",
       "      <td>To evaluate the pharmacokinetics (PK) of two d...</td>\n",
       "      <td>15/10/2011 00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Primary Endpoints: Pharmacokinetic Endpoints\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The subjectÃ¢ÂÂs participation in the trial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IRAS_projectID_67978</td>\n",
       "      <td>The use of carer assisted adherence therapy fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>PRIMARY Aim:\\nTo investigate if a seven week p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>The primary outcome measures for the study are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three to three and a half months for patients ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unique_ID                                              Title  \\\n",
       "0  IRAS_projectID_57754  Phase II, multicenter, randomized, adaptive, d...   \n",
       "1  IRAS_projectID_82035  A Randomized, Controlled, Long-term Safety Stu...   \n",
       "2  IRAS_projectID_64187  A Randomized, Double-Blind, Double-Dummy, Para...   \n",
       "3  IRAS_projectID_72673  Multi-Centre, Open-Label, Randomised Trial Inv...   \n",
       "4  IRAS_projectID_67978  The use of carer assisted adherence therapy fo...   \n",
       "\n",
       "  Phase                                          Objective          End_date  \\\n",
       "0    ii  To assess the efficacy and the safety of liqui...  31/05/2013 00:00   \n",
       "1     0  The principal objective of the study is to ass...  30/09/2013 00:00   \n",
       "2     0  To assess whether the efficacy of Ocrelizumab ...  31/03/2015 00:00   \n",
       "3     0  To evaluate the pharmacokinetics (PK) of two d...  15/10/2011 00:00   \n",
       "4     0  PRIMARY Aim:\\nTo investigate if a seven week p...               NaN   \n",
       "\n",
       "   Sample_size                                       1ry_endpoint  Treatment  \\\n",
       "0        150.0  The primary outcome measure is the Motor Funct...        NaN   \n",
       "1        450.0  The primary endpoint in this study is the chan...        NaN   \n",
       "2        800.0  The primary efficacy analysis for this trial w...        NaN   \n",
       "3         10.0  Primary Endpoints: Pharmacokinetic Endpoints\\n...        NaN   \n",
       "4        120.0  The primary outcome measures for the study are...        NaN   \n",
       "\n",
       "                                         LT_followup  \n",
       "0  Subjects will participate in the study for a t...  \n",
       "1  Subjects will be involved in this study for ju...  \n",
       "2  Screening 2 weeks\\nTreatment phase 96 weeks\\nS...  \n",
       "3  The subjectÃ¢ÂÂs participation in the trial ...  \n",
       "4  Three to three and a half months for patients ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].apply(preprocess_text)\n",
    "df['Objective'] = df['Objective'].apply(preprocess_text)\n",
    "df['1ry_endpoint'] = df['1ry_endpoint'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].apply(strip_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1ry_endpoint'] = df['1ry_endpoint'].apply(no_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Objective</th>\n",
       "      <th>End_date</th>\n",
       "      <th>Sample_size</th>\n",
       "      <th>1ry_endpoint</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>LT_followup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRAS_projectID_57754</td>\n",
       "      <td>phase ii multicenter randomized adaptive doubl...</td>\n",
       "      <td>ii</td>\n",
       "      <td>ass efficacy safety liquid suspension formulat...</td>\n",
       "      <td>31/05/2013 00:00</td>\n",
       "      <td>150.0</td>\n",
       "      <td>outcome measure motor function measure mfm d1 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjects will participate in the study for a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IRAS_projectID_82035</td>\n",
       "      <td>randomized controlled long term safety study e...</td>\n",
       "      <td>0</td>\n",
       "      <td>principal objective study ass long term safety...</td>\n",
       "      <td>30/09/2013 00:00</td>\n",
       "      <td>450.0</td>\n",
       "      <td>endpoint study change baseline total score nor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjects will be involved in this study for ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRAS_projectID_64187</td>\n",
       "      <td>randomized double blind double dummy parallel ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ass whether efficacy ocrelizumab given two dos...</td>\n",
       "      <td>31/03/2015 00:00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>efficacy analysis trial compare annualized pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Screening 2 weeks\\nTreatment phase 96 weeks\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IRAS_projectID_72673</td>\n",
       "      <td>multi centre open label randomised trial inves...</td>\n",
       "      <td>0</td>\n",
       "      <td>evaluate pharmacokinetics pk two different bat...</td>\n",
       "      <td>15/10/2011 00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>endpoint pharmacokinetic endpoint pk endpoint ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The subjectÃ¢ÂÂs participation in the trial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IRAS_projectID_67978</td>\n",
       "      <td>use carer assisted adherence therapy people pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>primary aim investigate seven week programme c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>outcome measure study morisky medication asses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three to three and a half months for patients ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unique_ID                                              Title  \\\n",
       "0  IRAS_projectID_57754  phase ii multicenter randomized adaptive doubl...   \n",
       "1  IRAS_projectID_82035  randomized controlled long term safety study e...   \n",
       "2  IRAS_projectID_64187  randomized double blind double dummy parallel ...   \n",
       "3  IRAS_projectID_72673  multi centre open label randomised trial inves...   \n",
       "4  IRAS_projectID_67978  use carer assisted adherence therapy people pa...   \n",
       "\n",
       "  Phase                                          Objective          End_date  \\\n",
       "0    ii  ass efficacy safety liquid suspension formulat...  31/05/2013 00:00   \n",
       "1     0  principal objective study ass long term safety...  30/09/2013 00:00   \n",
       "2     0  ass whether efficacy ocrelizumab given two dos...  31/03/2015 00:00   \n",
       "3     0  evaluate pharmacokinetics pk two different bat...  15/10/2011 00:00   \n",
       "4     0  primary aim investigate seven week programme c...               NaN   \n",
       "\n",
       "   Sample_size                                       1ry_endpoint  Treatment  \\\n",
       "0        150.0  outcome measure motor function measure mfm d1 ...        NaN   \n",
       "1        450.0  endpoint study change baseline total score nor...        NaN   \n",
       "2        800.0  efficacy analysis trial compare annualized pro...        NaN   \n",
       "3         10.0  endpoint pharmacokinetic endpoint pk endpoint ...        NaN   \n",
       "4        120.0  outcome measure study morisky medication asses...        NaN   \n",
       "\n",
       "                                         LT_followup  \n",
       "0  Subjects will participate in the study for a t...  \n",
       "1  Subjects will be involved in this study for ju...  \n",
       "2  Screening 2 weeks\\nTreatment phase 96 weeks\\nS...  \n",
       "3  The subjectÃ¢ÂÂs participation in the trial ...  \n",
       "4  Three to three and a half months for patients ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ns_hra.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions of primary endpoint type on NS-HRA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_hra = pd.read_csv('c:\\\\Users\\\\s2421127\\\\Documents\\\\NLP Project\\\\ObuayaO\\\\NLP project\\\\Chapter 3\\\\ns_hra.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('tfidf_train.pkl')\n",
    "scaler = joblib.load('scaler_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['Title', 'Objective', '1ry_endpoint'] # In the HRA REC forms, the primary endpoint and endpoint description are together\n",
    "X2 = ns_hra[text_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X2[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = vectorizer.transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = scaler.transform(X2) # I did this in the training so I guess I have to do that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_scores = mlp.predict_proba(X2) # How sure is the model on the predictions that it made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "euct_ns_pred = pd.DataFrame(confidence_scores, columns=['PFO_0', 'IO_1', 'SO_2'])\n",
    "euct_ns_pred['Predicted_label'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PFO_0      IO_1      SO_2  Predicted_label\n",
      "0  0.966957  0.023504  0.009539                0\n",
      "1  0.992628  0.005143  0.002228                0\n",
      "2  0.998461  0.001181  0.000358                0\n",
      "3  0.844298  0.087099  0.068603                0\n",
      "4  0.961650  0.026418  0.011932                0\n"
     ]
    }
   ],
   "source": [
    "print(euct_ns_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "euct_ns_pred.to_csv('euct_ns_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering_endpoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
